{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "earlier-investing",
   "metadata": {},
   "source": [
    "## Join the Duet Server the Data Owner 1 connected to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sized-session",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎤  🎸  ♪♪♪ Joining Duet ♫♫♫  🎻  🎹\n",
      "\n",
      "♫♫♫ >\u001b[93m DISCLAIMER\u001b[0m: \u001b[1mDuet is an experimental feature currently in beta.\n",
      "♫♫♫ > Use at your own risk.\n",
      "\u001b[0m\n",
      "\u001b[1m\n",
      "    > ❤️ \u001b[91mLove\u001b[0m \u001b[92mDuet\u001b[0m? \u001b[93mPlease\u001b[0m \u001b[94mconsider\u001b[0m \u001b[95msupporting\u001b[0m \u001b[91mour\u001b[0m \u001b[93mcommunity!\u001b[0m\n",
      "    > https://github.com/sponsors/OpenMined\u001b[1m\n",
      "\n",
      "♫♫♫ > Punching through firewall to OpenGrid Network Node at:\n",
      "♫♫♫ > http://localhost:5000/\n",
      "♫♫♫ >\n",
      "♫♫♫ > ...waiting for response from OpenGrid Network... \n",
      "♫♫♫ > \u001b[92mDONE!\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/holly/anaconda3/envs/pysyft/lib/python3.9/site-packages/aiortc/rtcdtlstransport.py:211: CryptographyDeprecationWarning: This version of cryptography contains a temporary pyOpenSSL fallback path. Upgrade pyOpenSSL now.\n",
      "  _openssl_assert(lib.SSL_CTX_use_certificate(ctx, self._cert._x509) == 1)  # type: ignore\n",
      "/home/holly/anaconda3/envs/pysyft/lib/python3.9/site-packages/aiortc/rtcdtlstransport.py:186: CryptographyDeprecationWarning: This version of cryptography contains a temporary pyOpenSSL fallback path. Upgrade pyOpenSSL now.\n",
      "  value=certificate_digest(self._cert._x509),  # type: ignore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "♫♫♫ > \u001b[92mCONNECTED!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import syft as sy\n",
    "duet1 = sy.join_duet(loopback=True,network_url=\"http://localhost:5000/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "racial-container",
   "metadata": {},
   "source": [
    "## Join the Duet Server the Data Owner 2 connected to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "centered-knife",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎤  🎸  ♪♪♪ Joining Duet ♫♫♫  🎻  🎹\n",
      "\n",
      "♫♫♫ >\u001b[93m DISCLAIMER\u001b[0m: \u001b[1mDuet is an experimental feature currently in beta.\n",
      "♫♫♫ > Use at your own risk.\n",
      "\u001b[0m\n",
      "\u001b[1m\n",
      "    > ❤️ \u001b[91mLove\u001b[0m \u001b[92mDuet\u001b[0m? \u001b[93mPlease\u001b[0m \u001b[94mconsider\u001b[0m \u001b[95msupporting\u001b[0m \u001b[91mour\u001b[0m \u001b[93mcommunity!\u001b[0m\n",
      "    > https://github.com/sponsors/OpenMined\u001b[1m\n",
      "\n",
      "♫♫♫ > Punching through firewall to OpenGrid Network Node at:\n",
      "♫♫♫ > http://localhost:5000/\n",
      "♫♫♫ >\n",
      "♫♫♫ > ...waiting for response from OpenGrid Network... \n",
      "♫♫♫ > \u001b[92mDONE!\u001b[0m\n",
      "\n",
      "♫♫♫ > \u001b[92mCONNECTED!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "duet2 = sy.join_duet(loopback=True,network_url=\"http://localhost:5000/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "wanted-upper",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Description</th>\n",
       "      <th>object_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;UID: 2e8eea1659ee4107b2effa8442b71063&gt;</td>\n",
       "      <td>[breast_cancer-data]</td>\n",
       "      <td>这是威斯康星洲临床科学中心开元的乳腺癌肿瘤数据集，共30维的特征数据</td>\n",
       "      <td>&lt;class 'torch.Tensor'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;UID: 73731e7e73834f598f26e922cb58040d&gt;</td>\n",
       "      <td>[breast_cancer-target]</td>\n",
       "      <td>这是数据标签，1代表良性肿瘤，0代表恶性肿瘤</td>\n",
       "      <td>&lt;class 'torch.Tensor'&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        ID                    Tags  \\\n",
       "0  <UID: 2e8eea1659ee4107b2effa8442b71063>    [breast_cancer-data]   \n",
       "1  <UID: 73731e7e73834f598f26e922cb58040d>  [breast_cancer-target]   \n",
       "\n",
       "                          Description             object_type  \n",
       "0  这是威斯康星洲临床科学中心开元的乳腺癌肿瘤数据集，共30维的特征数据  <class 'torch.Tensor'>  \n",
       "1              这是数据标签，1代表良性肿瘤，0代表恶性肿瘤  <class 'torch.Tensor'>  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duet1.store.pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "going-exposure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Description</th>\n",
       "      <th>object_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;UID: e558f4567b8a46c9afdc1c5c23068509&gt;</td>\n",
       "      <td>[breast_cancer-data]</td>\n",
       "      <td>这是威斯康星洲临床科学中心开元的乳腺癌肿瘤数据集，共30维的特征数据</td>\n",
       "      <td>&lt;class 'torch.Tensor'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;UID: 6e3469d501164615a4e783a72b2c0ddc&gt;</td>\n",
       "      <td>[breast_cancer-target]</td>\n",
       "      <td>这是数据标签，1代表良性肿瘤，0代表恶性肿瘤</td>\n",
       "      <td>&lt;class 'torch.Tensor'&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        ID                    Tags  \\\n",
       "0  <UID: e558f4567b8a46c9afdc1c5c23068509>    [breast_cancer-data]   \n",
       "1  <UID: 6e3469d501164615a4e783a72b2c0ddc>  [breast_cancer-target]   \n",
       "\n",
       "                          Description             object_type  \n",
       "0  这是威斯康星洲临床科学中心开元的乳腺癌肿瘤数据集，共30维的特征数据  <class 'torch.Tensor'>  \n",
       "1              这是数据标签，1代表良性肿瘤，0代表恶性肿瘤  <class 'torch.Tensor'>  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duet2.store.pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "responsible-cradle",
   "metadata": {},
   "source": [
    "## Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "719d8dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ptr1 = duet1.store[0]\n",
    "target_ptr1 = duet1.store[1]\n",
    "data_ptr2 = duet2.store[0]\n",
    "target_ptr2 = duet2.store[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c82076c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<syft.proxy.torch.TensorPointer object at 0x7f920e8a54f0>\n",
      "<syft.proxy.torch.TensorPointer object at 0x7f920e8a5790>\n",
      "<syft.proxy.torch.TensorPointer object at 0x7f920e8a5700>\n",
      "<syft.proxy.torch.TensorPointer object at 0x7f920e8a56a0>\n"
     ]
    }
   ],
   "source": [
    "print(data_ptr1)\n",
    "print(target_ptr1)\n",
    "print(data_ptr2)\n",
    "print(target_ptr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2ba9795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "这是威斯康星洲临床科学中心开元的乳腺癌肿瘤数据集，共30维的特征数据\n",
      "\n",
      "这是数据标签，1代表良性肿瘤，0代表恶性肿瘤\n"
     ]
    }
   ],
   "source": [
    "print(duet1.store.pandas[\"Description\"][0])\n",
    "print()\n",
    "print(duet1.store.pandas[\"Description\"][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seeing-savage",
   "metadata": {},
   "source": [
    "### Create Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91d89712",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1612d83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SyNet(sy.Module):\n",
    "    def __init__(self, torch_ref):\n",
    "        super(SyNet, self).__init__(torch_ref=torch_ref)\n",
    "        self.fc1 = self.torch_ref.nn.Linear(30, 10)\n",
    "        self.fc2 = self.torch_ref.nn.Linear(10, 1)\n",
    "        self.sigmoid=self.torch_ref.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b50468e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_model = SyNet(torch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f67d6bd",
   "metadata": {},
   "source": [
    "将模型发动给dataowner1和dataowner2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35a76823",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_model1 = local_model.send(duet1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5327689d",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_model2 = local_model.send(duet2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abaf2ed",
   "metadata": {},
   "source": [
    "远程的torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c62d13ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_torch1 = duet1.torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4f57676",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_torch2 = duet2.torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff735c44",
   "metadata": {},
   "source": [
    "设置优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41634ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "params1 = remote_model1.parameters()\n",
    "optim1 = remote_torch1.optim.Adam(params=params1, lr=0.01)\n",
    "params2 = remote_model2.parameters()\n",
    "optim2 = remote_torch2.optim.Adam(params=params2, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e89612cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def train(ownername,iterations, model, torch_ref, optim, data_ptr, target_ptr):\n",
    "\n",
    "    losses = []\n",
    "    #损失函数\n",
    "    cost=torch_ref.nn.BCELoss()\n",
    "    for i in range(iterations):\n",
    "        \n",
    "        #预测结果\n",
    "        output = model(data_ptr)\n",
    "        \n",
    "        #计算损失值\n",
    "        loss=cost(output,target_ptr)\n",
    "        \n",
    "        #在反向传播前先把梯度清零\n",
    "        optim.zero_grad()\n",
    "        \n",
    "        #反向传播,计算各参数对于损失loss的梯度\n",
    "        loss.backward()\n",
    "        \n",
    "        #根据刚刚反向传播得到的梯度更新模型参数\n",
    "        optim.step()        \n",
    "\n",
    "        loss_item = loss.item()\n",
    "        \n",
    "        loss_value = loss_item.get(\n",
    "            reason=\"To evaluate training progress\", request_block=True, timeout_secs=5,delete_obj=False)\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(ownername,\"--Epoch\", i, \"loss\", loss_value)\n",
    "\n",
    "        losses.append(loss_value)\n",
    "        \n",
    "    #返回模型\n",
    "    latest_model=model.get(\n",
    "        request_block=True,\n",
    "        reason=\"To run test and inference locally\",\n",
    "        timeout_secs=5,\n",
    "    )\n",
    "\n",
    "    return latest_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c817fb",
   "metadata": {},
   "source": [
    "设置迭代次数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "781c1182",
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0d433e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataowner2 --Epoch 0 loss 0.6857185363769531\n",
      "dataowner1 --Epoch 0 loss 0.6857185363769531\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "results = await asyncio.gather(\n",
    "        *[\n",
    "            train(\"dataowner1\",iteration, remote_model1, remote_torch1, optim1, data_ptr1, target_ptr1),\n",
    "            train(\"dataowner2\",iteration, remote_model2, remote_torch2, optim2, data_ptr2, target_ptr2)\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "590bda52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<__main__.SyNet object at 0x7f920d22f160>, <__main__.SyNet object at 0x7f920d22fb50>]\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65460cf8",
   "metadata": {},
   "source": [
    "## FedAvg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rubber-factor",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "creative-guide",
   "metadata": {},
   "source": [
    "#### Send one copy of the model to each data owner or client and train them remotely one by one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corporate-material",
   "metadata": {},
   "source": [
    "Dummy Target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlikely-digest",
   "metadata": {},
   "outputs": [],
   "source": [
    "target2_ptr = th.FloatTensor(np.array([35, 40, 45, 55, 60]).reshape(-1, 1))\n",
    "target2_ptr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loose-aging",
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration = 10\n",
    "losses = train(iteration, remote_model2, remote_torch2, optim2, data2_ptr, target2_ptr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grave-gravity",
   "metadata": {},
   "source": [
    "### Averaging Model Updates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "closed-bangladesh",
   "metadata": {},
   "source": [
    "Ideally, there will be a coordinator server with a secure aggreagtor who will get the model updates from different clients and make an aggregation. For the case of simplicity, in this example we will make the Data Sceintist server work as the coordinator."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hearing-passage",
   "metadata": {},
   "source": [
    "### Little sanity check!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eastern-silicon",
   "metadata": {},
   "outputs": [],
   "source": [
    "param1 = remote_model1.parameters().get(request_block=True,delete_obj=False)\n",
    "param2 = remote_model2.parameters().get(request_block=True,delete_obj=False)\n",
    "\n",
    "print(\"Base Model parameters:\")\n",
    "print(base_model.parameters())\n",
    "print()\n",
    "\n",
    "print(\"Remote model1 parameters:\")\n",
    "print(param1)\n",
    "print()\n",
    "\n",
    "print(\"Remote model2 parameters:\")\n",
    "print(param2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d38e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(remote_model1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preceding-beijing",
   "metadata": {},
   "source": [
    "As you can see, the remote model paramter values are different from the base model paramter values. That means the remote copies of our base model got trained and updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afraid-bishop",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_model1_updates = remote_model1.get(\n",
    "    request_block=True\n",
    ").state_dict()\n",
    "\n",
    "print(remote_model1_updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limiting-slope",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_model2_updates = remote_model2.get(\n",
    "    request_block=True\n",
    ").state_dict()\n",
    "\n",
    "print(remote_model2_updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personalized-measure",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apparent-platform",
   "metadata": {},
   "source": [
    "Let's do the aggregation of the weights. In this example, we will just calculate the average of corresponding weights from each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experimental-pulse",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_updates = OrderedDict()\n",
    "avg_updates[\"linear.weight\"] = (\n",
    "    remote_model1_updates[\"linear.weight\"] + remote_model2_updates[\"linear.weight\"]\n",
    ") / 2\n",
    "avg_updates[\"linear.bias\"] = (\n",
    "    remote_model1_updates[\"linear.bias\"] + remote_model2_updates[\"linear.bias\"]\n",
    ") / 2\n",
    "\n",
    "print(avg_updates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approximate-scotland",
   "metadata": {},
   "source": [
    "### Load aggregated weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungarian-chess",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_model = SyNet(torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exempt-gathering",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_model.load_state_dict(avg_updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beautiful-coating",
   "metadata": {},
   "outputs": [],
   "source": [
    "del avg_updates, remote_model1_updates, remote_model2_updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compressed-employer",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = th.FloatTensor(np.array([17, 25, 32, 50, 80]).reshape(-1, 1))\n",
    "test_target = th.FloatTensor(np.array([12, 15, 20, 30, 50]).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assured-amount",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for i in range(len(test_data)):\n",
    "        sample = test_data[i]\n",
    "        y_hat = combined_model(sample)\n",
    "\n",
    "        print(f\"Prediction: {y_hat.item()} Ground Truth: {test_target[i].item()}\")\n",
    "        preds.append(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charged-dragon",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for i in range(len(test_data)):\n",
    "        sample = test_data[i]\n",
    "        y_hat = base_model(sample)\n",
    "\n",
    "        print(f\"Prediction: {y_hat.item()} Ground Truth: {test_target[i].item()}\")\n",
    "        preds.append(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loose-textbook",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genetic-diploma",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "documented-italy",
   "metadata": {},
   "source": [
    "## Comparison to classical linear regression on centralised data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "external-recommendation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "in_dim = 1\n",
    "out_dim = 1\n",
    "\n",
    "\n",
    "class ClassicalLR(torch.nn.Module):\n",
    "    def __init__(self, torch):\n",
    "        super(ClassicalLR, self).__init__()\n",
    "        self.linear = torch.nn.Linear(in_dim, out_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "classical_model = ClassicalLR(torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "featured-antibody",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.FloatTensor(\n",
    "    np.array([5, 15, 25, 35, 45, 55, 60, 65, 75, 85, 95]).reshape(-1, 1)\n",
    ")\n",
    "target = torch.FloatTensor(\n",
    "    np.array([5, 10, 15, 22, 30, 38, 35, 40, 45, 55, 60]).reshape(-1, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adopted-costs",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classic_train(iterations, model, torch, optim, data, target, criterion):\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    for i in range(iterations):\n",
    "\n",
    "        optim.zero_grad()\n",
    "\n",
    "        output = model(data)\n",
    "\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        loss_item = loss.item()\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print(\"Epoch\", i, \"loss\", loss_item)\n",
    "\n",
    "        losses.append(loss_item)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optim.step()\n",
    "\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "balanced-lawyer",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = classical_model.parameters()\n",
    "optim = torch.optim.Adam(params=params, lr=0.1)\n",
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technical-gasoline",
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration = 100\n",
    "losses = classic_train(\n",
    "    iteration, classical_model, torch, optim, data, target, criterion\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compound-airline",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = th.FloatTensor(np.array([17, 25, 32, 50, 80]).reshape(-1, 1))\n",
    "test_target = th.FloatTensor(np.array([12, 15, 20, 30, 50]).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prospective-blood",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for i in range(len(test_data)):\n",
    "        sample = test_data[i]\n",
    "        y_hat = classical_model(sample)\n",
    "\n",
    "        print(f\"Prediction: {y_hat.item()} Ground Truth: {test_target[i].item()}\")\n",
    "        preds.append(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "veterinary-makeup",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
