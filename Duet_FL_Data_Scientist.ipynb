{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "earlier-investing",
   "metadata": {},
   "source": [
    "## Join the Duet Server the Data Owner 1 connected to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "sized-session",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤  ğŸ¸  â™ªâ™ªâ™ª Joining Duet â™«â™«â™«  ğŸ»  ğŸ¹\n",
      "\n",
      "â™«â™«â™« >\u001b[93m DISCLAIMER\u001b[0m: \u001b[1mDuet is an experimental feature currently in beta.\n",
      "â™«â™«â™« > Use at your own risk.\n",
      "\u001b[0m\n",
      "\u001b[1m\n",
      "    > â¤ï¸ \u001b[91mLove\u001b[0m \u001b[92mDuet\u001b[0m? \u001b[93mPlease\u001b[0m \u001b[94mconsider\u001b[0m \u001b[95msupporting\u001b[0m \u001b[91mour\u001b[0m \u001b[93mcommunity!\u001b[0m\n",
      "    > https://github.com/sponsors/OpenMined\u001b[1m\n",
      "\n",
      "â™«â™«â™« > Punching through firewall to OpenGrid Network Node at:\n",
      "â™«â™«â™« > http://localhost:5000/\n",
      "â™«â™«â™« >\n",
      "â™«â™«â™« > ...waiting for response from OpenGrid Network... \n",
      "â™«â™«â™« > \u001b[92mDONE!\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/holly/anaconda3/envs/pysyft/lib/python3.9/site-packages/aiortc/rtcdtlstransport.py:211: CryptographyDeprecationWarning: This version of cryptography contains a temporary pyOpenSSL fallback path. Upgrade pyOpenSSL now.\n",
      "  _openssl_assert(lib.SSL_CTX_use_certificate(ctx, self._cert._x509) == 1)  # type: ignore\n",
      "/home/holly/anaconda3/envs/pysyft/lib/python3.9/site-packages/aiortc/rtcdtlstransport.py:186: CryptographyDeprecationWarning: This version of cryptography contains a temporary pyOpenSSL fallback path. Upgrade pyOpenSSL now.\n",
      "  value=certificate_digest(self._cert._x509),  # type: ignore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â™«â™«â™« > \u001b[92mCONNECTED!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import syft as sy\n",
    "duet1 = sy.join_duet(loopback=True,network_url=\"http://localhost:5000/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "racial-container",
   "metadata": {},
   "source": [
    "## Join the Duet Server the Data Owner 2 connected to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "centered-knife",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤  ğŸ¸  â™ªâ™ªâ™ª Joining Duet â™«â™«â™«  ğŸ»  ğŸ¹\n",
      "\n",
      "â™«â™«â™« >\u001b[93m DISCLAIMER\u001b[0m: \u001b[1mDuet is an experimental feature currently in beta.\n",
      "â™«â™«â™« > Use at your own risk.\n",
      "\u001b[0m\n",
      "\u001b[1m\n",
      "    > â¤ï¸ \u001b[91mLove\u001b[0m \u001b[92mDuet\u001b[0m? \u001b[93mPlease\u001b[0m \u001b[94mconsider\u001b[0m \u001b[95msupporting\u001b[0m \u001b[91mour\u001b[0m \u001b[93mcommunity!\u001b[0m\n",
      "    > https://github.com/sponsors/OpenMined\u001b[1m\n",
      "\n",
      "â™«â™«â™« > Punching through firewall to OpenGrid Network Node at:\n",
      "â™«â™«â™« > http://localhost:5000/\n",
      "â™«â™«â™« >\n",
      "â™«â™«â™« > ...waiting for response from OpenGrid Network... \n",
      "â™«â™«â™« > \u001b[92mDONE!\u001b[0m\n",
      "\n",
      "â™«â™«â™« > \u001b[92mCONNECTED!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "duet2 = sy.join_duet(loopback=True,network_url=\"http://localhost:5000/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "wanted-upper",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Description</th>\n",
       "      <th>object_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;UID: 2e8eea1659ee4107b2effa8442b71063&gt;</td>\n",
       "      <td>[breast_cancer-data]</td>\n",
       "      <td>è¿™æ˜¯å¨æ–¯åº·æ˜Ÿæ´²ä¸´åºŠç§‘å­¦ä¸­å¿ƒå¼€å…ƒçš„ä¹³è…ºç™Œè‚¿ç˜¤æ•°æ®é›†ï¼Œå…±30ç»´çš„ç‰¹å¾æ•°æ®</td>\n",
       "      <td>&lt;class 'torch.Tensor'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;UID: 73731e7e73834f598f26e922cb58040d&gt;</td>\n",
       "      <td>[breast_cancer-target]</td>\n",
       "      <td>è¿™æ˜¯æ•°æ®æ ‡ç­¾ï¼Œ1ä»£è¡¨è‰¯æ€§è‚¿ç˜¤ï¼Œ0ä»£è¡¨æ¶æ€§è‚¿ç˜¤</td>\n",
       "      <td>&lt;class 'torch.Tensor'&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        ID                    Tags  \\\n",
       "0  <UID: 2e8eea1659ee4107b2effa8442b71063>    [breast_cancer-data]   \n",
       "1  <UID: 73731e7e73834f598f26e922cb58040d>  [breast_cancer-target]   \n",
       "\n",
       "                          Description             object_type  \n",
       "0  è¿™æ˜¯å¨æ–¯åº·æ˜Ÿæ´²ä¸´åºŠç§‘å­¦ä¸­å¿ƒå¼€å…ƒçš„ä¹³è…ºç™Œè‚¿ç˜¤æ•°æ®é›†ï¼Œå…±30ç»´çš„ç‰¹å¾æ•°æ®  <class 'torch.Tensor'>  \n",
       "1              è¿™æ˜¯æ•°æ®æ ‡ç­¾ï¼Œ1ä»£è¡¨è‰¯æ€§è‚¿ç˜¤ï¼Œ0ä»£è¡¨æ¶æ€§è‚¿ç˜¤  <class 'torch.Tensor'>  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duet1.store.pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "going-exposure",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Description</th>\n",
       "      <th>object_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;UID: e558f4567b8a46c9afdc1c5c23068509&gt;</td>\n",
       "      <td>[breast_cancer-data]</td>\n",
       "      <td>è¿™æ˜¯å¨æ–¯åº·æ˜Ÿæ´²ä¸´åºŠç§‘å­¦ä¸­å¿ƒå¼€å…ƒçš„ä¹³è…ºç™Œè‚¿ç˜¤æ•°æ®é›†ï¼Œå…±30ç»´çš„ç‰¹å¾æ•°æ®</td>\n",
       "      <td>&lt;class 'torch.Tensor'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;UID: 6e3469d501164615a4e783a72b2c0ddc&gt;</td>\n",
       "      <td>[breast_cancer-target]</td>\n",
       "      <td>è¿™æ˜¯æ•°æ®æ ‡ç­¾ï¼Œ1ä»£è¡¨è‰¯æ€§è‚¿ç˜¤ï¼Œ0ä»£è¡¨æ¶æ€§è‚¿ç˜¤</td>\n",
       "      <td>&lt;class 'torch.Tensor'&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        ID                    Tags  \\\n",
       "0  <UID: e558f4567b8a46c9afdc1c5c23068509>    [breast_cancer-data]   \n",
       "1  <UID: 6e3469d501164615a4e783a72b2c0ddc>  [breast_cancer-target]   \n",
       "\n",
       "                          Description             object_type  \n",
       "0  è¿™æ˜¯å¨æ–¯åº·æ˜Ÿæ´²ä¸´åºŠç§‘å­¦ä¸­å¿ƒå¼€å…ƒçš„ä¹³è…ºç™Œè‚¿ç˜¤æ•°æ®é›†ï¼Œå…±30ç»´çš„ç‰¹å¾æ•°æ®  <class 'torch.Tensor'>  \n",
       "1              è¿™æ˜¯æ•°æ®æ ‡ç­¾ï¼Œ1ä»£è¡¨è‰¯æ€§è‚¿ç˜¤ï¼Œ0ä»£è¡¨æ¶æ€§è‚¿ç˜¤  <class 'torch.Tensor'>  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duet2.store.pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "responsible-cradle",
   "metadata": {},
   "source": [
    "## Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "719d8dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ptr1 = duet1.store[0]\n",
    "target_ptr1 = duet1.store[1]\n",
    "data_ptr2 = duet2.store[0]\n",
    "target_ptr2 = duet2.store[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c82076c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<syft.proxy.torch.TensorPointer object at 0x7f920e8a54f0>\n",
      "<syft.proxy.torch.TensorPointer object at 0x7f920e8a5790>\n",
      "<syft.proxy.torch.TensorPointer object at 0x7f920e8a5700>\n",
      "<syft.proxy.torch.TensorPointer object at 0x7f920e8a56a0>\n"
     ]
    }
   ],
   "source": [
    "print(data_ptr1)\n",
    "print(target_ptr1)\n",
    "print(data_ptr2)\n",
    "print(target_ptr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2ba9795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è¿™æ˜¯å¨æ–¯åº·æ˜Ÿæ´²ä¸´åºŠç§‘å­¦ä¸­å¿ƒå¼€å…ƒçš„ä¹³è…ºç™Œè‚¿ç˜¤æ•°æ®é›†ï¼Œå…±30ç»´çš„ç‰¹å¾æ•°æ®\n",
      "\n",
      "è¿™æ˜¯æ•°æ®æ ‡ç­¾ï¼Œ1ä»£è¡¨è‰¯æ€§è‚¿ç˜¤ï¼Œ0ä»£è¡¨æ¶æ€§è‚¿ç˜¤\n"
     ]
    }
   ],
   "source": [
    "print(duet1.store.pandas[\"Description\"][0])\n",
    "print()\n",
    "print(duet1.store.pandas[\"Description\"][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seeing-savage",
   "metadata": {},
   "source": [
    "### Create Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91d89712",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1612d83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SyNet(sy.Module):\n",
    "    def __init__(self, torch_ref):\n",
    "        super(SyNet, self).__init__(torch_ref=torch_ref)\n",
    "        self.fc1 = self.torch_ref.nn.Linear(30, 10)\n",
    "        self.fc2 = self.torch_ref.nn.Linear(10, 1)\n",
    "        self.sigmoid=self.torch_ref.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.sigmoid(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b50468e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_model = SyNet(torch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f67d6bd",
   "metadata": {},
   "source": [
    "å°†æ¨¡å‹å‘åŠ¨ç»™dataowner1å’Œdataowner2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35a76823",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_model1 = local_model.send(duet1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5327689d",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_model2 = local_model.send(duet2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abaf2ed",
   "metadata": {},
   "source": [
    "è¿œç¨‹çš„torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c62d13ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_torch1 = duet1.torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4f57676",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_torch2 = duet2.torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff735c44",
   "metadata": {},
   "source": [
    "è®¾ç½®ä¼˜åŒ–å™¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41634ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "params1 = remote_model1.parameters()\n",
    "optim1 = remote_torch1.optim.Adam(params=params1, lr=0.01)\n",
    "params2 = remote_model2.parameters()\n",
    "optim2 = remote_torch2.optim.Adam(params=params2, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e89612cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def train(ownername,iterations, model, torch_ref, optim, data_ptr, target_ptr):\n",
    "\n",
    "    losses = []\n",
    "    #æŸå¤±å‡½æ•°\n",
    "    cost=torch_ref.nn.BCELoss()\n",
    "    for i in range(iterations):\n",
    "        \n",
    "        #é¢„æµ‹ç»“æœ\n",
    "        output = model(data_ptr)\n",
    "        \n",
    "        #è®¡ç®—æŸå¤±å€¼\n",
    "        loss=cost(output,target_ptr)\n",
    "        \n",
    "        #åœ¨åå‘ä¼ æ’­å‰å…ˆæŠŠæ¢¯åº¦æ¸…é›¶\n",
    "        optim.zero_grad()\n",
    "        \n",
    "        #åå‘ä¼ æ’­,è®¡ç®—å„å‚æ•°å¯¹äºæŸå¤±lossçš„æ¢¯åº¦\n",
    "        loss.backward()\n",
    "        \n",
    "        #æ ¹æ®åˆšåˆšåå‘ä¼ æ’­å¾—åˆ°çš„æ¢¯åº¦æ›´æ–°æ¨¡å‹å‚æ•°\n",
    "        optim.step()        \n",
    "\n",
    "        loss_item = loss.item()\n",
    "        \n",
    "        loss_value = loss_item.get(\n",
    "            reason=\"To evaluate training progress\", request_block=True, timeout_secs=5,delete_obj=False)\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(ownername,\"--Epoch\", i, \"loss\", loss_value)\n",
    "\n",
    "        losses.append(loss_value)\n",
    "        \n",
    "    #è¿”å›æ¨¡å‹\n",
    "    latest_model=model.get(\n",
    "        request_block=True,\n",
    "        reason=\"To run test and inference locally\",\n",
    "        timeout_secs=5,\n",
    "    )\n",
    "\n",
    "    return latest_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c817fb",
   "metadata": {},
   "source": [
    "è®¾ç½®è¿­ä»£æ¬¡æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "781c1182",
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0d433e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataowner2 --Epoch 0 loss 0.6857185363769531\n",
      "dataowner1 --Epoch 0 loss 0.6857185363769531\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "results = await asyncio.gather(\n",
    "        *[\n",
    "            train(\"dataowner1\",iteration, remote_model1, remote_torch1, optim1, data_ptr1, target_ptr1),\n",
    "            train(\"dataowner2\",iteration, remote_model2, remote_torch2, optim2, data_ptr2, target_ptr2)\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "590bda52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<__main__.SyNet object at 0x7f920d22f160>, <__main__.SyNet object at 0x7f920d22fb50>]\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65460cf8",
   "metadata": {},
   "source": [
    "## FedAvg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rubber-factor",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "creative-guide",
   "metadata": {},
   "source": [
    "#### Send one copy of the model to each data owner or client and train them remotely one by one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corporate-material",
   "metadata": {},
   "source": [
    "Dummy Target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlikely-digest",
   "metadata": {},
   "outputs": [],
   "source": [
    "target2_ptr = th.FloatTensor(np.array([35, 40, 45, 55, 60]).reshape(-1, 1))\n",
    "target2_ptr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loose-aging",
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration = 10\n",
    "losses = train(iteration, remote_model2, remote_torch2, optim2, data2_ptr, target2_ptr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grave-gravity",
   "metadata": {},
   "source": [
    "### Averaging Model Updates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "closed-bangladesh",
   "metadata": {},
   "source": [
    "Ideally, there will be a coordinator server with a secure aggreagtor who will get the model updates from different clients and make an aggregation. For the case of simplicity, in this example we will make the Data Sceintist server work as the coordinator."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hearing-passage",
   "metadata": {},
   "source": [
    "### Little sanity check!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eastern-silicon",
   "metadata": {},
   "outputs": [],
   "source": [
    "param1 = remote_model1.parameters().get(request_block=True,delete_obj=False)\n",
    "param2 = remote_model2.parameters().get(request_block=True,delete_obj=False)\n",
    "\n",
    "print(\"Base Model parameters:\")\n",
    "print(base_model.parameters())\n",
    "print()\n",
    "\n",
    "print(\"Remote model1 parameters:\")\n",
    "print(param1)\n",
    "print()\n",
    "\n",
    "print(\"Remote model2 parameters:\")\n",
    "print(param2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d38e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(remote_model1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preceding-beijing",
   "metadata": {},
   "source": [
    "As you can see, the remote model paramter values are different from the base model paramter values. That means the remote copies of our base model got trained and updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afraid-bishop",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_model1_updates = remote_model1.get(\n",
    "    request_block=True\n",
    ").state_dict()\n",
    "\n",
    "print(remote_model1_updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limiting-slope",
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_model2_updates = remote_model2.get(\n",
    "    request_block=True\n",
    ").state_dict()\n",
    "\n",
    "print(remote_model2_updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "personalized-measure",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "apparent-platform",
   "metadata": {},
   "source": [
    "Let's do the aggregation of the weights. In this example, we will just calculate the average of corresponding weights from each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experimental-pulse",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_updates = OrderedDict()\n",
    "avg_updates[\"linear.weight\"] = (\n",
    "    remote_model1_updates[\"linear.weight\"] + remote_model2_updates[\"linear.weight\"]\n",
    ") / 2\n",
    "avg_updates[\"linear.bias\"] = (\n",
    "    remote_model1_updates[\"linear.bias\"] + remote_model2_updates[\"linear.bias\"]\n",
    ") / 2\n",
    "\n",
    "print(avg_updates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approximate-scotland",
   "metadata": {},
   "source": [
    "### Load aggregated weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungarian-chess",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_model = SyNet(torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exempt-gathering",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_model.load_state_dict(avg_updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beautiful-coating",
   "metadata": {},
   "outputs": [],
   "source": [
    "del avg_updates, remote_model1_updates, remote_model2_updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compressed-employer",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = th.FloatTensor(np.array([17, 25, 32, 50, 80]).reshape(-1, 1))\n",
    "test_target = th.FloatTensor(np.array([12, 15, 20, 30, 50]).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assured-amount",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for i in range(len(test_data)):\n",
    "        sample = test_data[i]\n",
    "        y_hat = combined_model(sample)\n",
    "\n",
    "        print(f\"Prediction: {y_hat.item()} Ground Truth: {test_target[i].item()}\")\n",
    "        preds.append(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charged-dragon",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for i in range(len(test_data)):\n",
    "        sample = test_data[i]\n",
    "        y_hat = base_model(sample)\n",
    "\n",
    "        print(f\"Prediction: {y_hat.item()} Ground Truth: {test_target[i].item()}\")\n",
    "        preds.append(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loose-textbook",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genetic-diploma",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "documented-italy",
   "metadata": {},
   "source": [
    "## Comparison to classical linear regression on centralised data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "external-recommendation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "in_dim = 1\n",
    "out_dim = 1\n",
    "\n",
    "\n",
    "class ClassicalLR(torch.nn.Module):\n",
    "    def __init__(self, torch):\n",
    "        super(ClassicalLR, self).__init__()\n",
    "        self.linear = torch.nn.Linear(in_dim, out_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "classical_model = ClassicalLR(torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "featured-antibody",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.FloatTensor(\n",
    "    np.array([5, 15, 25, 35, 45, 55, 60, 65, 75, 85, 95]).reshape(-1, 1)\n",
    ")\n",
    "target = torch.FloatTensor(\n",
    "    np.array([5, 10, 15, 22, 30, 38, 35, 40, 45, 55, 60]).reshape(-1, 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adopted-costs",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classic_train(iterations, model, torch, optim, data, target, criterion):\n",
    "\n",
    "    losses = []\n",
    "\n",
    "    for i in range(iterations):\n",
    "\n",
    "        optim.zero_grad()\n",
    "\n",
    "        output = model(data)\n",
    "\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        loss_item = loss.item()\n",
    "\n",
    "        if i % 10 == 0:\n",
    "            print(\"Epoch\", i, \"loss\", loss_item)\n",
    "\n",
    "        losses.append(loss_item)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optim.step()\n",
    "\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "balanced-lawyer",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = classical_model.parameters()\n",
    "optim = torch.optim.Adam(params=params, lr=0.1)\n",
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technical-gasoline",
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration = 100\n",
    "losses = classic_train(\n",
    "    iteration, classical_model, torch, optim, data, target, criterion\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compound-airline",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = th.FloatTensor(np.array([17, 25, 32, 50, 80]).reshape(-1, 1))\n",
    "test_target = th.FloatTensor(np.array([12, 15, 20, 30, 50]).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prospective-blood",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = []\n",
    "with torch.no_grad():\n",
    "    for i in range(len(test_data)):\n",
    "        sample = test_data[i]\n",
    "        y_hat = classical_model(sample)\n",
    "\n",
    "        print(f\"Prediction: {y_hat.item()} Ground Truth: {test_target[i].item()}\")\n",
    "        preds.append(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "veterinary-makeup",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
